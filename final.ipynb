{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41a8faa-042b-492c-85c7-ba7594397603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import keras\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2d00f6-485e-4769-aa8f-283f796e3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import plotly \n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "#from wordcloud import WordCloud\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1917af98-bd80-4661-8623-0988d0338355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.tsv', sep='\\t')\n",
    "x_test=pd.read_csv('test_stg2.tsv', sep='\\t')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25fe98c-30f7-47fc-9adf-935c2b862999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# Combining all the above stundents \n",
    "from tqdm import tqdm\n",
    "def preprocess_text(text_data):\n",
    "    preprocessed_text = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(text_data):\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0fc2b3c-9ac8-44a5-a9d3-9ebc4bb25089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(input_, model):\n",
    "    \"\"\"this function predicts the price basing on the trained model\"\"\"\n",
    "    batchsize = 256\n",
    "    preds = model.predict(input_.tocsr(), batch_size=batchsize)\n",
    "    preds = np.exp(preds)+1\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9063701-355b-4de3-ba1a-d4591a250343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def handle_data(data):\n",
    "    def transform_category_name(category_name):\n",
    "        try:\n",
    "            main, sub1, sub2= category_name.split('/')\n",
    "            return main, sub1, sub2\n",
    "        except:\n",
    "            return ('missing', 'missing', 'missing')\n",
    "        \n",
    "    def branded(brand_name):\n",
    "        is_branded=[]\n",
    "        for i in data['brand_name']:\n",
    "            if i=='missing': \n",
    "                is_branded.append(0) \n",
    "            else: \n",
    "                is_branded.append(1)\n",
    "            return is_branded\n",
    "\n",
    "    if type(data)==type(pd.DataFrame()):   #checking if it is a dataframe or not\n",
    "        data['category_name'].fillna(value='missing',inplace=True)\n",
    "        \n",
    "        data['category_main'], data['category_sub1'], data['category_sub2'] = zip(*data['category_name'].apply(transform_category_name))\n",
    "        data['brand_name'].fillna(value='missing',inplace=True)\n",
    "        data['is_branded']=zip(*data['brand_name'].apply(branded))\n",
    "        data['item_description'].fillna(value='No description yet',inplace=True)\n",
    "        data['name']= data['name']\n",
    "        data['shipping']=data['shipping']\n",
    "        data['item_condition_id']=data['item_condition_id']\n",
    "        \n",
    "        if 'price' in data.columns:\n",
    "            return data[['name','item_description','brand_name','category_main','category_sub1','category_sub2','is_branded','shipping','item_condition_id','price']]\n",
    "        else:\n",
    "            return data[['name','item_description','brand_name','category_main','category_sub1','category_sub2','is_branded','shipping','item_condition_id']]\n",
    "        \n",
    "    else:      #if the given data is a data point\n",
    "        if type(data['category_name'])==type(float()):  #checking for nan values in category_name\n",
    "            data['category_name'].fillna(\"missing\",inplace=True)\n",
    "            data['category_main'], data['category_sub1'], data['category_sub2'] = zip(*data['category_name'].apply(transform_category_name))\n",
    "\n",
    "        if type(data['brand_name'])==type(float()):     #checking for nan values in brand_name\n",
    "            data['brand_name'].fillna(value='missing',inplace=True)\n",
    "            data['is_branded']=zip(*data['brand_name'].apply(branded))\n",
    "\n",
    "        if type(data['item_description'])==type(float()):  #checking for nan values in item_description\n",
    "            data['item_description'].fillna(\"No description yet\",inplace=True)\n",
    "            #data['category_main'], data['category_sub1'], data['category_sub2'] =data['category_name'].split('/')\n",
    "        if data['brand_name']=='missing': \n",
    "            data[\"is_branded\"]=0\n",
    "        else: \n",
    "            data[\"is_branded\"]=1\n",
    "        data['name']= data['name']\n",
    "        data['shipping']=data['shipping']\n",
    "        data['item_condition_id']=data['item_condition_id']\n",
    "\n",
    "        if 'price' in dict(data).keys():  #if price exits we will return it\n",
    "            return data[['name','item_description','brand_name','category_main','category_sub1','category_sub2','is_branded','shipping','item_condition_id','price']]\n",
    "        else:\n",
    "            return data[['name','item_description','brand_name','category_main','category_sub1','category_sub2','is_branded','shipping','item_condition_id']]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f3f27a8-b141-4006-98be-ffdeb5854954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_suggestion(X):\n",
    "\n",
    "    X=handle_data(X)          \n",
    "    if 'price' in dict(X).keys():\n",
    "        target=X['price']  #checking if price contains in it or not\n",
    "    else:\n",
    "        target='we predicted it'\n",
    "    vectorizer_name=pickle.load(open(\"vectorizer_name.pkl\",\"rb\"))\n",
    "    bow_name=vectorizer_name.transform(X['name'].values)  #name vectorization\n",
    "    \n",
    "    vectorizer_item=pickle.load(open(\"vectorizer_item.pkl\", 'rb'))\n",
    "    bow_item=vectorizer_item.transform(X['item_description'].values) \n",
    "\n",
    "    vectorizer_cat=pickle.load(open(\"vectorizer_cat.pkl\",\"rb\"))\n",
    "    bow_cat=vectorizer_cat.transform(X['category_main'].values) \n",
    "    \n",
    "    vectorizer_sub1=pickle.load(open(\"vectorizer_sub1.pkl\",\"rb\"))\n",
    "    bow_sub1=vectorizer_sub1.transform(X['category_sub1'].values)\n",
    "    #text vectorization\n",
    "    \n",
    "    vectorizer_sub2=pickle.load(open(\"vectorizer_sub2.pkl\",\"rb\"))\n",
    "    bow_sub2=vectorizer_sub2.transform(X['category_sub2'].values)\n",
    "    #text vectorization\n",
    "    \n",
    "    vectorizer_brand=pickle.load(open(\"vectorizer_brand.pkl\",\"rb\"))\n",
    "    bow_brand=vectorizer_brand.transform(X['brand_name'].values)  #text vectorization\n",
    "\n",
    "    is_brand_oe=pickle.load(open(\"is_branded_oe.pkl\",\"rb\"))\n",
    "    is_brand=is_brand_oe.transform(X[['is_branded']])\n",
    "    \n",
    "    item_cond_oe=pickle.load(open(\"item_cond.pkl\",\"rb\"))\n",
    "    item_cond=item_cond_oe.transform(X[['item_condition_id']])\n",
    "    \n",
    "    shipping_oe=pickle.load(open(\"shipping_oe.pkl\",\"rb\"))\n",
    "    shipping=shipping_oe.transform(X[['shipping']])\n",
    "    \n",
    "\n",
    "\n",
    "    concat=hstack([bow_name,bow_item,bow_cat,bow_sub1,bow_sub2,bow_brand,is_brand,item_cond,shipping])   #concatinating all the features\n",
    "    best_model = load_model('baseline_mlp_model_epochs:001-val_loss:0.183.hdf5')\n",
    "\n",
    "    #preds = best_model.predict(X_te.tocsr())[:, 0]\n",
    "    predicted_price=prediction(concat,best_model)\n",
    "    return predicted_price[0],target  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3d53586-5c8a-4283-a4f1-cbad78d088cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for the given product is: 5.254732131958008\n"
     ]
    }
   ],
   "source": [
    "predicted,target=price_suggestion(x_test.reindex([110]))  #some random train data point.\n",
    "if target!='we predicted it':\n",
    "  print(\"Predicted price is: {} and Actual price of the product is: {}\".format(predicted,target))\n",
    "else:\n",
    "  print(\"Predicted price for the given product is: {}\".format(predicted[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dba402b-8e79-48ba-a9cf-9ce3709bf613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def error_metric(X,Y):\n",
    "  \"\"\"this function returns the rmsle error on the target and predicted score\n",
    "     Input_format: X: data point(must be 7 or 8 dimensional datapoint) (vector)\n",
    "                   Y: float \n",
    "     Output format: float (rmsle score) \"\"\"\n",
    "  predicted_score=price_suggestion(X)\n",
    "  return rmsle([Y],[predicted_score[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d6433d7-f81d-4b13-90d3-2f8f57efd9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0776d690-6b4a-4aee-ad97-10aefe82e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on given datapoint is:  1.3077167567860957\n",
      "RMSLE on given datapoint is:  0.8080904444622989\n"
     ]
    }
   ],
   "source": [
    "error=error_metric(data.reindex([10]),data.reindex([10])['price'])  #some random train data point\n",
    "print(\"RMSLE on given datapoint is: \",error)\n",
    "\n",
    "error=error_metric(data.reindex([170]),data.reindex([170])['price'])  #some random train data point\n",
    "print(\"RMSLE on given datapoint is: \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67391cca-2b31-4748-bcc9-e1394e08e1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
